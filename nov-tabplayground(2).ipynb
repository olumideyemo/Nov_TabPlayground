{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-02T00:59:49.297444Z","iopub.execute_input":"2021-12-02T00:59:49.298216Z","iopub.status.idle":"2021-12-02T00:59:49.330953Z","shell.execute_reply.started":"2021-12-02T00:59:49.298069Z","shell.execute_reply":"2021-12-02T00:59:49.329927Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Load packages\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OrdinalEncoder\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import tree","metadata":{"execution":{"iopub.status.busy":"2021-12-02T00:59:49.334404Z","iopub.execute_input":"2021-12-02T00:59:49.334635Z","iopub.status.idle":"2021-12-02T00:59:50.471419Z","shell.execute_reply.started":"2021-12-02T00:59:49.334608Z","shell.execute_reply":"2021-12-02T00:59:50.470499Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Load training data\ndf = pd.read_csv(\"../input/tabular-playground-series-nov-2021/train.csv\") \n# check for missing values\n#df.isnull().sum()\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-02T00:59:50.475187Z","iopub.execute_input":"2021-12-02T00:59:50.475546Z","iopub.status.idle":"2021-12-02T01:00:05.434079Z","shell.execute_reply.started":"2021-12-02T00:59:50.475503Z","shell.execute_reply":"2021-12-02T01:00:05.431889Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Split the data into X and y\noutput_col = ['target']\nX = df.drop(['id', 'target'], axis=1)\ny = df[output_col]\n#y.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-02T01:00:05.435435Z","iopub.execute_input":"2021-12-02T01:00:05.435755Z","iopub.status.idle":"2021-12-02T01:00:05.621548Z","shell.execute_reply.started":"2021-12-02T01:00:05.435711Z","shell.execute_reply":"2021-12-02T01:00:05.620588Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#fScale X values with StandardScaler\n#scaler = StandardScaler()\nscaler = StandardScaler()\nsclX = scaler.fit_transform(X)\n\nsclX = pd.DataFrame(sclX)\n#columns=['a', 'b', 'c']\nsclX.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-02T01:00:05.623449Z","iopub.execute_input":"2021-12-02T01:00:05.624100Z","iopub.status.idle":"2021-12-02T01:00:07.420639Z","shell.execute_reply.started":"2021-12-02T01:00:05.624051Z","shell.execute_reply":"2021-12-02T01:00:07.419705Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Lasso (L1) Regression: Plot is flat \nfrom sklearn.linear_model import Lasso\n\ndf_columns = sclX.columns\n\n# Instantiate a lasso regressor: lasso\nlasso = Lasso(alpha=0.4, normalize=True)\n\n# Fit the regressor to the data\nlasso.fit(sclX,y)\n\n# Compute and print the coefficients\nlasso_coef = lasso.fit(sclX,y).coef_\nprint(lasso_coef)\n\n# Plot the coefficients\nplt.plot(range(len(df_columns)), lasso_coef)\nplt.xticks(range(len(df_columns)), df_columns.values, rotation=60)\nplt.margins(0.02)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-02T01:00:07.421823Z","iopub.execute_input":"2021-12-02T01:00:07.422046Z","iopub.status.idle":"2021-12-02T01:00:10.739524Z","shell.execute_reply.started":"2021-12-02T01:00:07.422019Z","shell.execute_reply":"2021-12-02T01:00:10.738664Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Split the data into training and test data\nX_train, X_test, y_train, y_test =  train_test_split(sclX,y,test_size = 0.30, random_state= 44)\n\n# Choose the criterion and max depth of the tree you want to use\nCRITERION = 'gini'\nMAX_DEPTH = 3\n\n# Set up the DT classifier\ndt_clf = DecisionTreeClassifier(criterion=CRITERION, max_depth=MAX_DEPTH, random_state=43)\n\n# Train the DT classifier\ndt_clf.fit(X_train, y_train)\n\n# Evaluate the DT on the test set\ny_pred = dt_clf.predict(X_test)\nprint(f'Model accuracy score with criterion {CRITERION} index: {accuracy_score(y_test, y_pred):.4f}')","metadata":{"execution":{"iopub.status.busy":"2021-12-02T01:00:10.740810Z","iopub.execute_input":"2021-12-02T01:00:10.741038Z","iopub.status.idle":"2021-12-02T01:00:38.819229Z","shell.execute_reply.started":"2021-12-02T01:00:10.741007Z","shell.execute_reply":"2021-12-02T01:00:38.818318Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import xgboost as xgb # XGBoost typically uses the alias \"xgb\"\n\n# Instatiate a XGBClassifier \nxgb_clf = xgb.XGBClassifier(n_estimators= 12, random_state=43, eval_metric='mlogloss')\n\n# Inspect the parameters\n#xgb_clf.get_params()\n\n# make predictions for test data\nxgb_clf.fit(X_train, y_train)\n\n# Evaluate the DT on the test set\ny_pred_xg = xgb_clf.predict(X_test)\n\n# evaluate predictions\naccuracy = accuracy_score(y_test, y_pred_xg)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100))\n# print(\"Baseline accuracy:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2021-12-02T01:00:38.820830Z","iopub.execute_input":"2021-12-02T01:00:38.821195Z","iopub.status.idle":"2021-12-02T01:01:44.836194Z","shell.execute_reply.started":"2021-12-02T01:00:38.821136Z","shell.execute_reply":"2021-12-02T01:01:44.835256Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Checking feature importance\nimport matplotlib\nmatplotlib.rcParams['figure.figsize'] = (10.0, 16)\n\n# Plot feature importance\nxgb.plot_importance(xgb_clf)","metadata":{"execution":{"iopub.status.busy":"2021-12-02T01:01:44.837818Z","iopub.execute_input":"2021-12-02T01:01:44.838750Z","iopub.status.idle":"2021-12-02T01:01:46.033341Z","shell.execute_reply.started":"2021-12-02T01:01:44.838693Z","shell.execute_reply":"2021-12-02T01:01:46.032425Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Plot gain instead of weight\nxgb.plot_importance(xgb_clf, importance_type=\"gain\")","metadata":{"execution":{"iopub.status.busy":"2021-12-02T01:01:46.034604Z","iopub.execute_input":"2021-12-02T01:01:46.034885Z","iopub.status.idle":"2021-12-02T01:01:47.540623Z","shell.execute_reply.started":"2021-12-02T01:01:46.034853Z","shell.execute_reply":"2021-12-02T01:01:47.539757Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# RandomSearch CV\n\n#from sklearn.model_selection import RandomizedSearchCV\n\n# Define a parameter grid\n#rs_param_grid = {\n     #max_depth: values from 3 to 12\n#    'max_depth': list((range(3,12))),\n     #alpha: values 0, .001, .01, .1\n#    'alpha': [0,0.001, 0.01,0.1,1],\n     #subsample: values 0.25,0.5,0.75, 1\n#    'subsample': [0.5,0.75,1],\n     #learning rate: ten values between 0.01 - 0.5\n#    'learning_rate': np.linspace(0.01,0.5, 10),\n     #n_estimators: values 10, 25, 40\n#    'n_estimators': [10, 25, 40]\n#    }\n\n\n# Insantiate XGBoost Clasifier \n#xgb_clf_rs = xgb.XGBClassifier(eval_metric='mlogloss', random_state=43)\n\n# Instantiate RandomizedSearchCV()\n#xgb_rs = RandomizedSearchCV(estimator=xgb_clf_rs,param_distributions=rs_param_grid, \n#                                cv=3, n_iter=5, verbose=2, random_state=43)\n\n# Train the model on the training set\n#xgb_rs.fit(X_train, y_train)\n\n# Print the best parameters and highest accuracy\n#print(\"Best parameters found: \", xgb_rs.best_params_)\n#print(\"Best accuracy found: \", xgb_rs.best_score_)","metadata":{"execution":{"iopub.status.busy":"2021-12-02T01:01:47.543282Z","iopub.execute_input":"2021-12-02T01:01:47.544026Z","iopub.status.idle":"2021-12-02T01:01:47.548967Z","shell.execute_reply.started":"2021-12-02T01:01:47.543977Z","shell.execute_reply":"2021-12-02T01:01:47.548146Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#instantiate final model\nfinal_xgb_clf = xgb.XGBClassifier(eval_metric='mlogloss', random_state=43, \n                               subsample= 1, n_estimators= 40, max_depth= 6,\n                               learning_rate= 0.44555555555555554, alpha= 0.01)\n# make predictions for test data\nfinal_xgb_clf.fit(X_train, y_train)\n\n# Evaluate the DT on the test set\ny_pred_xg_final = final_xgb_clf.predict(X_test)\n\n# evaluate predictions\naccuracy = accuracy_score(y_test, y_pred_xg_final)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100))","metadata":{"execution":{"iopub.status.busy":"2021-12-02T01:01:47.550064Z","iopub.execute_input":"2021-12-02T01:01:47.550359Z","iopub.status.idle":"2021-12-02T01:05:11.295232Z","shell.execute_reply.started":"2021-12-02T01:01:47.550322Z","shell.execute_reply":"2021-12-02T01:05:11.294194Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Load test data\ntest_df = pd.read_csv(\"../input/tabular-playground-series-nov-2021/test.csv\") \ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-02T01:05:11.296505Z","iopub.execute_input":"2021-12-02T01:05:11.296730Z","iopub.status.idle":"2021-12-02T01:05:23.757712Z","shell.execute_reply.started":"2021-12-02T01:05:11.296698Z","shell.execute_reply":"2021-12-02T01:05:23.756747Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Split the data into X and y\nfinal_X = test_df.drop(['id'], axis=1)\n# y = test_df.assign(target = y_pred_test)\n#final_X.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-02T01:05:23.759078Z","iopub.execute_input":"2021-12-02T01:05:23.759334Z","iopub.status.idle":"2021-12-02T01:05:23.964261Z","shell.execute_reply.started":"2021-12-02T01:05:23.759305Z","shell.execute_reply":"2021-12-02T01:05:23.963383Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Evaluate the DT on the test set\nfinal_y_pred = final_xgb_clf.predict(final_X)\n\noutput = pd.DataFrame({'id': test_df.id, 'target': final_y_pred})\noutput.to_csv('./submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")\noutput.info","metadata":{"execution":{"iopub.status.busy":"2021-12-02T01:05:23.965298Z","iopub.execute_input":"2021-12-02T01:05:23.965502Z","iopub.status.idle":"2021-12-02T01:05:25.393991Z","shell.execute_reply.started":"2021-12-02T01:05:23.965478Z","shell.execute_reply":"2021-12-02T01:05:25.393005Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# review sample submission data to check before submission\n# Load data\n#df = pd.read_csv(\"../input/tabular-playground-series-nov-2021/sample_submission.csv\") \n#df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-02T01:05:25.395387Z","iopub.execute_input":"2021-12-02T01:05:25.395887Z","iopub.status.idle":"2021-12-02T01:05:25.399791Z","shell.execute_reply.started":"2021-12-02T01:05:25.395847Z","shell.execute_reply":"2021-12-02T01:05:25.398862Z"},"trusted":true},"execution_count":16,"outputs":[]}]}